---
title: バギング
title-en: Bagging
---

# 概要

= **B**ootstrap **AGG**regat**ING**

# 学習の流れ

1. 以下の操作を $n$ 回繰り返す
	1. 学習データからブートストラップ（重複を許してランダムサンプリング）により $m$ 個の標本を抽出
	2. この標本でモデルを学習
2. 得られた $n$ 個のモデルを組み合わせて最終出力を計算
	1. ex. 回帰問題：各モデルの出力の平均値を計算
	2. ex. 分類問題：各モデルの多数決を取る

![bagging](https://user-images.githubusercontent.com/13412823/259004212-a5fdf3cc-5ef6-4596-bd93-86795807fbee.png)

# バギングの特徴

variance を下げ、過学習を抑えられる。


# バギングの適用例

バギングを応用したアルゴリズムとして有名なものにランダムフォレストがある。