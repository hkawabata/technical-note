---
title: パーセプトロン
---

# パーセプトロンとは

分類問題を解くアルゴリズムの1つ。

- 二値分類
- 単純パーセプトロンでは線形分離可能な問題しか解けない

# 基本原理

## 問題設定

入力値（特徴量） $$x_1, \cdots, x_m$$ に対し、分類ラベル $$y$$ を出力するモデルを作りたい。

各入力値に重み $$w_1, \cdots, w_m$$ をかけて和を取った

$$z = \displaystyle \sum_{j=1}^{m} w_j x_j$$

を **総入力** と呼び、$$z$$ が閾値 $$\theta$$ 以上か否かで二値分類を行う。

$$
y = \phi(z) =
\begin{cases}
1  & (z \ge \theta ) \\
-1 & (z \lt \theta )
\end{cases}
$$

活性化関数 $$\phi(z)$$ はステップ関数となる。

本問題は、最適な重み $$w_1, \cdots, w_m$$ 及び閾値 $$\theta$$ を求める問題に帰着される。

ここで、総入力 $$z$$ にゼロ番目の入力・重みとして $$x_0 = 1, w_0 = - \theta$$ を与えることで、閾値 $$\theta$$ を重みの1つとして扱える：

$$z = - \theta + w_1 x_1 + \cdots + w_m x_m = \displaystyle \sum_{j=0}^{m} w_j x_j$$

$$
y = \phi(z) =
\begin{cases}
1  & (z \ge 0 ) \\
-1 & (z \lt 0 )
\end{cases}
$$


## 学習規則

1. 重みをゼロ or 値の小さい乱数で初期化
2. $$i$$ 番目の学習サンプル $$\boldsymbol{x}^{(i)} = ( x_0^{(i)}, \cdots, x_m^{(i)} )$$ ごとに以下の手順を実行
    1. 現時点のモデルを使い、$$\boldsymbol{x}^{(i)}$$ に対するラベル $$\hat y^{(i)}$$ を計算
    2. 計算した $$\hat y$$ が正解分類ラベル $$y^{(i)}$$ と異なっていたら、計算結果を正解へ近づける方向へ重みを更新
3. 収束するまで2を繰り返す

$$\hat y^{(i)} = x_0^{(i)} w_0 + \cdots + x_m^{(i)} w_m$$

$$w_j \leftarrow w_j + \eta (y^{(i)} - \hat y^{(i)}) x_j^{(i)}$$

ここで $$\eta (0 \lt \eta \le 1)$$ は学習率であり、1度に重みを更新する大きさを表す。

### 学習率の大きさと収束

- $$\eta$$ が大きすぎると永遠に収束しないので、十分に小さく取る必要がある
- $$\eta$$ が小さいほど重みの更新がゆっくりなので、学習が収束するまでに必要な繰り返し回数が大きくなる

### 線形分離性

- 学習用データセットが完全に線形分離できる場合、パーセプトロンは収束する
- 学習用データセットが完全には線形分離できない場合、以下のような収束条件を定めないと永遠に収束しない
  - 最大何回まで繰り返すか（エポック）
  - 判定誤りを何件まで許容するか




