---
title: PR 曲線 (適合率-再現率曲線)
title-en: Precision-Recall Curve
---
# 概要

分類モデルの評価関数の閾値を色々と変えて、縦軸に適合度 $P$（Precision）、横軸に再現率 $R$（Recall）を取ってプロットした曲線。  
モデルの性能を評価する際に用いられる。

- 適合度 $P$：モデルが陽性と判定したうち、実際に陽性である割合
- 再現率 $R$：実際に陽性であるもののうち、モデルが陽性と判定した割合

$$
\begin{eqnarray}
    P &=& \cfrac{TP}{TP+FP}
    \\
    R &=& \cfrac{TP}{TP+FN}
\end{eqnarray}
$$

# PR 曲線の描画

使用したデータ：

- 横軸：モデルによる予測ラベル（確率）
- 縦軸：データの度数
- 正解ラベルの陽性・陰性それぞれについて度数分布を描画

![pr_hist](https://user-images.githubusercontent.com/13412823/284030843-cee6391a-bf4c-40cd-8a6e-e8de24c10a8b.png)


これを元に描いた PR 曲線：

![pr-curve](https://user-images.githubusercontent.com/13412823/284031108-f8271974-de01-4832-97e3-f3cba4e94b0a.png)



# PR 曲線の見方

## 定性的な理解

**グラフのカーブが右上にある（= 再現率が上がっても適合率が下がりにくい）ほど良いモデルであると言える**。  
1. 複数のモデルの PR 曲線を比較し、最も良いモデルを選ぶ
2. 選んだモデルにおいてどの閾値を適用するか？ → ビジネス要求に合う閾値を選ぶ
    1. 適合率重視（= 偽陽性が少ないことを重視）
    2. 再現率重視（= 偽陽性が多少混じってでも、正解を取りこぼさないことを重視）
    3. 程良く適合率・再現率のバランスを取りたい
    4. etc...

## PR-AUC

PR 曲線の下部の面積（Area Under the Curve）。
グラフのカーブが右上に寄っているほど PR-AUC は大きくなるので、PR-AUC が大きいほど良いモデルと評価できる。


# ROC 曲線と PR 曲線の使い分け

PR 曲線と同様に機械学習モデルの評価に使うグラフに [ROC 曲線](roc-auc.md)がある。

- ROC曲線を使うと良いケース
    - 正例と負例のデータ数が同程度なデータセットを用いる場合
- PR 曲線を使うと良いケース
    - 正例と負例のデータ数が不均衡なデータセットを用いる場合

具体例として、以下の2つのケースを考える。

## 具体例1：Positive (P) と Negative (N) の正解数が同じで N の判別能力が低いモデルの場合

|  | 予測 = P | 予測 = N |
| :-- | :-- | :-- |
| 正解 = P | TP:90 | FN:10 |
| 正解 = N | FP:40 | TN:60 |

- ROC 曲線のパラメータ
    - TPR = 0.90
    - FPR = 0.40
- PR 曲線のパラメータ
    - Recall = 0.90
    - Precision = 0.69

## 具体例2：Positive (P) より Negative (N) の正解数が極端に多い場合

|  | 予測 = P | 予測 = N |
| :-- | :-- | :-- |
| 正解 = P | TP:90 | FN:10 |
| 正解 = N | FP:100 | TN:900 |

- ROC 曲線のパラメータ
    - TPR = 0.90
    - FPR = 0.10
- PR 曲線のパラメータ
    - Recall = 0.90
    - Precision = 0.47

→ ROC 曲線を使うと、Precision が低いことが捉えられず、結果が良く見えてしまう。
